<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Stolen from Sergey and Jon Barron */
  /* with significant help from Debidatta Dwibedi's webpage */
  a {
    color: #1772d0;
    text-decoration:none;
  }
  a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
  }
  body,td,th {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px
  }
  strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;


    font-size: 14px
  }
  strongred {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    color: 'red'

    font-size: 14px
  }
  heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;*/


    font-size: 15px;
    font-weight: 700
  }
</style>
<!-- <link rel="icon" type="image/png" href="seal_icon.png"> -->
<script type="text/javascript" src="hidebib.js"></script>
<title>Shashank Tripathi</title>
<meta name="Shashank Tripathi&#39;s CMU Homepage" http-equiv="Content-Type" content="Shashank Tripathi&#39;s Homepage">

<link href="css" rel="stylesheet" type="text/css">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90857215-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>

  <table width="960" border="0" align="center" cellspacing="0" cellpadding="20">
    <tbody><tr>
      <td>
        <p align="center"><font size="7">Shashank Tripathi</font><br>
        </p><table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle" align="justify">



              <p>I am a Masters student in <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cmu.edu/">CMU</a>. I am advised by Prof. <a href="http://www.cs.cmu.edu/~kkitani/"> Kris Kitani</a>.
                <br>

              </p><p align="center">
                <a href="mailto:shashank.tripathi123@gmail.com">Email</a> &nbsp;/&nbsp;
                <!-- <a href="assets/DebidattaDwibedi_CV.pdf">CV</a> &nbsp;/&nbsp; -->
                <a href="https://scholar.google.com/citations?user=CANstcsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/sha2nkt"> GitHub</a>&nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/shashanktripathi123/"> LinkedIn </a> /
                <a href="assets/CV_Shashank_CMU_V16_TOC.pdf"> CV </a>
                <!-- <a href="https://www.twitter.com/debidatta/"> Twitter </a> -->
              </p>

              <!--
            </p><p align="center">
              <a href="#publications">Publications</a> &nbsp;/&nbsp;

              <a href="#patents">Patents</a> &nbsp/&nbsp
              <a href="#talks">Talks</a>&nbsp;/&nbsp;
              <a href="#theses">Theses</a>&nbsp;/&nbsp;
              <a href="#misc">Misc</a>
            </p>
              -->


          </td>
          <td width="33%"><img src="assets/shashank.jpg" width="90%" style="background-repeat: no-repeat;background-position: 50%;border-radius: 50%;width: 200px;height: 200px;"></td>
        </tr>
      </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">



        <tbody><tr><td>
          <h2>Research</h2>

          I want to build intelligent AI agents with human-level vision capabilities.
          <br/><br/>
          My research lies at the intersection of machine learning, deep-learning, computer vision and robotics. Presently, I am working on applications of both 2D and 3D synthetic data in tasks such as object detection, pose-estimation, semantic segmentation and activity-forecasting. I am also interested in analysing deep neural-net sparsity for model compression.
          <br/><br/>
          In the past, I have worked on visual-servoing, medical-image analysis, pedestrian-detection and reinforcement learning.
          
        </td></tr>

      </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tbody><tr><td>
          <h2 id="publications">Publications</h2></td></tr>

        <tr>
            <td width="42%" valign="top"><a href="assets/c2f_img.PNG"><img src="assets/c2f_img.PNG" width="90%" height="30%" style="border-style: none"></a>
            </td><td width="58%" valign="top">
              <p><a href="https://www.eurekaselect.com/node/159218/article/c2f-coarse-to-fine-vision-control-system-for-automated-microassembly" id="C2F">
                <heading>C2F: Coarse-to-Fine Vision Control System for Automated Microassembly</heading></a><br>
                Shashank Tripathi, Devesh Jain and Himanshu Dutt Sharma<br>
                <em><a href="https://benthamscience.com/journals/nanoscience-and-nanotechnology-asia/">Nanotechnology and Nanoscience-Asia 2018 </a></href> </em>
                <br>
                <br>
                Automated, visual-servoing based closed loop system to perform 3D micromanipulation and microassembly tasks<br>

              </p>

              <div class="paper" id="c2f">
                <a href="https://drive.google.com/file/d/0B0keZAN_TLL9VmZ2dlAxRlYzYjA/view">paper</a> |
                <a href="javascript:toggleblock(&#39;c2f_abs&#39;)">abstract</a> |
                <a href="https://www.youtube.com/watch?v=lAagBmqj_Nw">video</a>


                <!-- <a shape="rect" href="javascript:togglebib(&#39;c2f&#39;)" class="togglebib">bibtex</a> -->


                <p align="justify"> <i id="c2f_abs" style="display: none;">In this paper, authors present the development of a completely automated system to perform 3D micromanipulation and microassembly tasks. The microassembly workstation consists of a 3 degree-of-freedom (DOF) MM3A® micromanipulator arm attached to a microgripper, two 2 DOF PI® linear micromotion stages, one optical microscope coupled with a CCD image sensor, and two CMOS cameras for coarse vision. The whole control strategy is subdivided into sequential vision based routines: manipulator detection and coarse alignment, autofocus and fine alignment of microgripper, target object detection, and performing the required assembly tasks. A section comparing various objective functions useful in the autofocusing regime is included. The control system is built entirely in the image frame, eliminating the need for system calibration, hence improving speed of operation. A micromanipulation experiment performing pick- and-place of a micromesh is illustrated. This demonstrates a three-fold reduction in setup and run time for fundamental micromanipulation tasks, as compared to manual operation. Accuracy, repeatability and reliability of the programmed system is analyzed.</i> </p>

                <!-- <div style="white-space: pre-wrap; display: none;" class="bib">
                  @article{dwibedi2016deep,
                  title={Deep cuboid detection: Beyond 2d bounding boxes},
                  author={Dwibedi, Debidatta and Malisiewicz, Tomasz and Badrinarayanan, Vijay and Rabinovich, Andrew},
                  journal={arXiv preprint arXiv:1611.10010},
                  year={2016}
                } -->
              </div>
            </div>
          </td>
        </tr>

        <tr>
          <td width="42%" valign="top"><a href="assets/isbi_image.png"><img src="assets/isbi_image.PNG" width="100%" height="40%" style="border-style: none"></a>
          </td><td width="58%" valign="top">
            <p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950682" id="ALZHEIMERS">
              <heading>Sub-cortical Shape Morphology and Voxel-based Features for Alzheimer's Disease Classification</heading></a><br>
              Shashank Tripathi, Seyed Hossein Nozadi,  <a href="https://www.researchgate.net/profile/Mahsa_Shakeri2">Mahsa Shakeri</a> and <a href="http://www.polymtl.ca/expertises/en/kadoury-samuel">Samuel Kadoury</a><br>
              <em><a href="https://biomedicalimaging.org/2017/">IEEE International Symposium on Biomedical Imaging (ISBI) 2017 </a></href> </em>
              <br>
              <br>
              Alzheimer's disease patient classification using a combination of grey-matter voxel-based intensity variations and 3D structural (shape) features extracted from MRI brain scans <br>

            </p>

            <div class="paper" id="sub_cortical">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950682">paper</a> |
              <a href="javascript:toggleblock(&#39;sub_cortical_abs&#39;)">abstract</a> |
              <a shape="rect" href="javascript:togglebib(&#39;sub_cortical&#39;)" class="togglebib">bibtex</a> |
              <a href="assets/sub_cortical_poster.pdf">poster</a>

              <!-- <a href="https://sites.google.com/corp/view/actionablerepresentations/"> project </a> -->


              <p align="justify"> <i id="sub_cortical_abs" style="display: none;"> Neurodegenerative pathologies, such as Alzheimer’s disease, are linked with morphological alterations and tissue variations in subcortical structures which can be assessed from medical imaging and biological data. In this work, we present an unsupervised framework for the classification of Alzheimer’s disease (AD) patients, stratifying patients into four diagnostic groups, namely: AD, early Mild Cognitive Impairment (MCI), late MCI and normal controls by combining shape and voxel-based features from 12 sub-cortical areas. An automated anatomical labeling using an atlas-based segmentation approach is proposed to extract multiple regions of interest known to be linked with AD progression. We take advantage of gray-matter voxel-based intensity variations and structural alterations extracted with a spherical harmonics framework to learn the discriminative features between multiple diagnostic classes. The proposed method is validated on 600 patients from the ADNI database by training binary SVM classifiers of dimensionality reduced features, using both linear and RBF kernels. Results show near state-of-the-art approaches in classification accuracy (>88%), especially for the more challenging discrimination tasks: AD vs. LMCI (76.81%), NC vs. EMCI (75.46%) and EMCI vs. LMCI (70.95%). By combining multimodality features, this pipeline demonstrates the potential by exploiting complementary features to improve cognitive assessment. </i> </p>

              <div style="white-space: pre-wrap; display: none;" class="bib">
                @inproceedings{tripathi2017sub,
                  title={Sub-cortical shape morphology and voxel-based features for Alzheimer's disease classification},
                  author={Tripathi, Shashank and Nozadi, Seyed Hossein and Shakeri, Mahsa and Kadoury, Samuel},
                  booktitle={Biomedical Imaging (ISBI 2017), 2017 IEEE 14th International Symposium on},
                  pages={991--994},
                  year={2017},
                  organization={IEEE}
                }
            </div>
          </div>
        </td>
      </tr>

      <tr>
        <td width="42%" valign="top"><a href="assets/miccai_img.png"><img src="assets/miccai_img.png" width="100%" height="15%" style="border-style: none"></a>
        </td><td width="58%" valign="top">
          <p><a href="https://link.springer.com/chapter/10.1007/978-3-319-51237-2_2" id="DEEP_SPECTRAL">
            <heading>Deep Spectral-Based Shape Features for Alzheimer’s Disease Classification</heading></a><br>
            <a href="https://www.researchgate.net/profile/Mahsa_Shakeri2">Mahsa Shakeri</a>, <a href="https://profs.etsmtl.ca/hlombaert/">Hervé Lombaert</a>, Shashank Tripathi and <a href="http://www.polymtl.ca/expertises/en/kadoury-samuel">Samuel Kadoury</a><br>
            <em><a href="http://www.miccai2016.org/en/">MICCAI Spectral and Shape Analysis in Medical Imaging (SeSAMI) 2016</a></em>
            <br>
            <br>
            Alzheimer's disease classification by using deep learning variational auto-encoder on shape based features<br>

          </p>

          <div class="paper" id="deepspectral">
            <a href="https://link.springer.com/chapter/10.1007/978-3-319-51237-2_2">paper</a> |
            <a href="javascript:toggleblock(&#39;deepspectral_abs&#39;)">abstract</a> |
            <a shape="rect" href="javascript:togglebib(&#39;deepspectral&#39;)" class="togglebib">bibtex</a> |
            <!-- <a href="https://github.com/debidatta/syndata-generation">code</a> |
            <a href="assets/cutpaste_poster.pdf">poster</a> -->


            <p align="justify"> <i id="deepspectral_abs" style="display: none;">Alzheimer’s disease (AD) and mild cognitive impairment (MCI) are the most prevalent neurodegenerative brain diseases in elderly population. Recent studies on medical imaging and biological data have shown morphological alterations of subcortical structures in patients with these pathologies. In this work, we take advantage of these structural deformations for classification purposes. First, triangulated surface meshes are extracted from segmented hippocampus structures in MRI and point-to-point correspondences are established among population of surfaces using a spectral matching method. Then, a deep learning variational auto-encoder is applied on the vertex coordinates of the mesh models to learn the low dimensional feature representation. A multi-layer perceptrons using softmax activation is trained simultaneously to classify Alzheimer’s patients from normal subjects. Experiments on ADNI dataset demonstrate the potential of the proposed method in classification of normal individuals from early MCI (EMCI), late MCI (LMCI), and AD subjects with classification rates outperforming standard SVM based approach.</i> </p>

            <div style="white-space: pre-wrap; display: none;" class="bib">
              @inproceedings{shakeri2016deep,
              title={Deep spectral-based shape features for alzheimer’s disease classification},
              author={Shakeri, Mahsa and Lombaert, Herve and Tripathi, Shashank and Kadoury, Samuel and Alzheimer’s Disease Neuroimaging Initiative and others},
              booktitle={International Workshop on Spectral and Shape Analysis in Medical Imaging},
              pages={15--24},
              year={2016},
              organization={Springer}
            }
          </div>
        </div>
      </td>
    </tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr><td>
    <h2 id="misc">Miscellaneous</h2>
    Some other unpublished work:
  </td></tr>
</tbody></table>

<table width="100%" align="center" border="0" cellpadding="20">
  <tbody><tr>
    <td width="42%" valign="top"><a href="assets/supercnn_img.png"><img src="assets/supercnn_img.png" width="100%" height="30%" style="border-style: none"></a>
    </td><td width="58%" valign="center">
      <p>
        <a href="assets/learning_salient_objects.pdf"><heading>Learning Salient Objects in a Scene using Superpixel-augmented Convolutional Neural Networks</heading></a><br>
      </p>
      <div class="paper" id="super_cnn">
        <a href="assets/learning_salient_objects.pdf"> report </a> |
        <a href="assets/SuperCNN.pdf"> slides </a> |
        <a href="https://github.com/sha2nkt/SuperCNN"> code </a>




      </div>

    </td>
  </tr>
  <tr>
    <td width="42%" valign="top"><a href="assets/tracking_combined.gif"><img src="assets/tracking_combined.gif" width="100%" style="border-style: none"></a>

    </td><td width="58%" valign="center">
      <p>
        <a href="assets/tracking.pdf"><heading>Moving object detection, tracking and classification from an unsteady camera</heading></a><br>
      </p>
      <div class="paper" id="tracking">
          <a href="assets/tracking.pdf"> slides </a> |
          <a href="https://www.youtube.com/watch?v=g_nTKhVyPHw"> video </a>


    </td>


  </tr>


  <tr>
    <td width="42%" valign="top"><a href="assets/model_combined.gif"><img src="assets/model_combined.gif" width="100%" height="120%" style="border-style: none"></a>
    </td><td width="58%" valign="center">
      <p>
        <a href="assets/deep-rl-final.pdf"><heading>Towards integrating model dynamics for sample efficient reinforcement learning</heading></a><br>
      </p>
      <div class="paper" id="model_based">
          <a href="assets/deep-rl-final.pdf"> report </a> |
          <a href="https://github.com/sha2nkt/QD_learning"> code </a>
      </div>

    </td>
  </tr>   

</tbody></table>

</td>
</tr>
</tbody></table>

<script xml:space="preserve" language="JavaScript">
  hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('pa13_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('cuboid_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('mftcn_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('temporal_abs');
</script>


</body></html>